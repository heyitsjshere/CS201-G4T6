{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4823bd05",
   "metadata": {},
   "source": [
    "# TopK-Airlines: Experimental Results Analysis\n",
    "\n",
    "This notebook analyzes the performance of different data structures (Heap, Balanced BST, Skip List) for maintaining Top-K airlines by average rating.\n",
    "\n",
    "## Experiment Overview\n",
    "- **Dataset**: Skytrax airline reviews\n",
    "- **Operations**: Insert, Search, Delete\n",
    "- **Metrics**: Runtime, Memory usage, Top-K accuracy\n",
    "- **Data Structures**: Min/Max Heap, Balanced BST, Skip List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5331e",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc58b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d46ca5",
   "metadata": {},
   "source": [
    "## Load Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from experiments\n",
    "results_path = Path('../results/results.csv')\n",
    "\n",
    "if results_path.exists():\n",
    "    results_df = pd.read_csv(results_path)\n",
    "    print(f\"Loaded {len(results_df)} experimental results\")\n",
    "    display(results_df.head(10))\n",
    "else:\n",
    "    print(\"⚠️ No results found. Please run experiments first using: python src/experiment.py\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9602df5",
   "metadata": {},
   "source": [
    "## Data Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    print(\"\\n=== Summary Statistics ===\")\n",
    "    print(f\"\\nData structures tested: {results_df['structure'].unique()}\")\n",
    "    print(f\"\\nOperations tested: {results_df['operation'].unique() if 'operation' in results_df.columns else 'N/A'}\")\n",
    "    print(f\"\\nData size range: {results_df['n'].min()} - {results_df['n'].max()}\")\n",
    "    \n",
    "    # Group statistics\n",
    "    summary = results_df.groupby('structure').agg({\n",
    "        'avg_time': ['mean', 'std', 'min', 'max']\n",
    "    }).round(6)\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3fb61",
   "metadata": {},
   "source": [
    "## Visualization 1: Runtime Comparison Across Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ab217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    # Plot each data structure\n",
    "    structures = results_df['structure'].unique()\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(structures)))\n",
    "    \n",
    "    for idx, structure in enumerate(structures):\n",
    "        data = results_df[results_df['structure'] == structure].sort_values('n')\n",
    "        ax.plot(data['n'], data['avg_time'], \n",
    "                marker='o', linewidth=2, markersize=8,\n",
    "                label=structure, color=colors[idx], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Number of Operations (n)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Average Time (seconds)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Runtime Comparison: Top-K Data Structures', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(fontsize=11, loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/runtime_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Plot saved to results/runtime_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbde094",
   "metadata": {},
   "source": [
    "## Visualization 2: Runtime Comparison by Operation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7839377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty and 'operation' in results_df.columns:\n",
    "    operations = results_df['operation'].unique()\n",
    "    n_ops = len(operations)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_ops, figsize=(6*n_ops, 5))\n",
    "    if n_ops == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, operation in enumerate(operations):\n",
    "        ax = axes[idx]\n",
    "        op_data = results_df[results_df['operation'] == operation]\n",
    "        \n",
    "        for structure in op_data['structure'].unique():\n",
    "            data = op_data[op_data['structure'] == structure].sort_values('n')\n",
    "            ax.plot(data['n'], data['avg_time'], \n",
    "                   marker='o', linewidth=2, label=structure, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Number of Operations (n)', fontsize=11)\n",
    "        ax.set_ylabel('Average Time (seconds)', fontsize=11)\n",
    "        ax.set_title(f'{operation.capitalize()} Operation', fontsize=12, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/runtime_by_operation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Plot saved to results/runtime_by_operation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecace2",
   "metadata": {},
   "source": [
    "## Visualization 3: Performance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Create pivot table for heatmap\n",
    "    pivot_data = results_df.pivot_table(\n",
    "        values='avg_time', \n",
    "        index='structure', \n",
    "        columns='n', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    im = ax.imshow(pivot_data.values, cmap='YlOrRd', aspect='auto')\n",
    "    \n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks(np.arange(len(pivot_data.columns)))\n",
    "    ax.set_yticks(np.arange(len(pivot_data.index)))\n",
    "    ax.set_xticklabels(pivot_data.columns)\n",
    "    ax.set_yticklabels(pivot_data.index)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Average Time (seconds)', fontsize=11)\n",
    "    \n",
    "    # Add values to cells\n",
    "    for i in range(len(pivot_data.index)):\n",
    "        for j in range(len(pivot_data.columns)):\n",
    "            text = ax.text(j, i, f'{pivot_data.values[i, j]:.4f}',\n",
    "                         ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Number of Operations (n)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Data Structure', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Performance Heatmap: Average Runtime', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/performance_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Plot saved to results/performance_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6515fea",
   "metadata": {},
   "source": [
    "## Visualization 4: Scalability Analysis (Log Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Linear scale\n",
    "    for structure in results_df['structure'].unique():\n",
    "        data = results_df[results_df['structure'] == structure].sort_values('n')\n",
    "        ax1.plot(data['n'], data['avg_time'], marker='o', label=structure, linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Number of Operations (n)', fontsize=11)\n",
    "    ax1.set_ylabel('Average Time (seconds)', fontsize=11)\n",
    "    ax1.set_title('Linear Scale', fontsize=12, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log-log scale\n",
    "    for structure in results_df['structure'].unique():\n",
    "        data = results_df[results_df['structure'] == structure].sort_values('n')\n",
    "        ax2.loglog(data['n'], data['avg_time'], marker='o', label=structure, linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Number of Operations (n)', fontsize=11)\n",
    "    ax2.set_ylabel('Average Time (seconds)', fontsize=11)\n",
    "    ax2.set_title('Log-Log Scale', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    plt.suptitle('Scalability Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/scalability_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Plot saved to results/scalability_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc21a4",
   "metadata": {},
   "source": [
    "## Analysis & Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "#### 1. **Heap Performance**\n",
    "- Best for: \n",
    "- Time Complexity: O(log n) for insert/delete, O(1) for peek\n",
    "- Observations:\n",
    "\n",
    "#### 2. **Balanced BST Performance**\n",
    "- Best for:\n",
    "- Time Complexity: O(log n) for all operations\n",
    "- Observations:\n",
    "\n",
    "#### 3. **Skip List Performance**\n",
    "- Best for:\n",
    "- Time Complexity: O(log n) average case\n",
    "- Observations:\n",
    "\n",
    "### Recommendations\n",
    "- **Use Heap when**: You primarily need to find min/max and occasional insertions\n",
    "- **Use BST when**: You need balanced performance across all operations\n",
    "- **Use Skip List when**: You need probabilistic guarantees and easier implementation\n",
    "\n",
    "### Future Work\n",
    "- [ ] Test with larger datasets (1M+ reviews)\n",
    "- [ ] Implement memory usage tracking\n",
    "- [ ] Add concurrent access benchmarks\n",
    "- [ ] Test with different K values (Top-5, Top-20, Top-50)\n",
    "- [ ] Analyze cache performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4afd3",
   "metadata": {},
   "source": [
    "## Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Generate summary report\n",
    "    report = []\n",
    "    report.append(\"=\" * 60)\n",
    "    report.append(\"TopK-Airlines Experiment Summary Report\")\n",
    "    report.append(\"=\" * 60)\n",
    "    report.append(f\"\\nTotal experiments run: {len(results_df)}\")\n",
    "    report.append(f\"Data structures tested: {', '.join(results_df['structure'].unique())}\")\n",
    "    report.append(f\"\\nPerformance Summary (average runtime in seconds):\")\n",
    "    report.append(\"-\" * 60)\n",
    "    \n",
    "    for structure in results_df['structure'].unique():\n",
    "        avg_time = results_df[results_df['structure'] == structure]['avg_time'].mean()\n",
    "        report.append(f\"{structure:20s}: {avg_time:.6f}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    # Save report\n",
    "    with open('../results/summary_report.txt', 'w') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(\"\\n✅ Summary report saved to results/summary_report.txt\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
